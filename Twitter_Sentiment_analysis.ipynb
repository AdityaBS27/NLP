{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Sentiment analysis (OPEC).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkS-VWPggVAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mount the google drive to import the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7ROPuhKm17T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import all the library nesccary for the execution \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from textblob import Word\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import OrderedDict\n",
        "from itertools import *\n",
        "from itertools import repeat, chain, islice\n",
        "from collections import Counter\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import precision_score,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_curve,  roc_auc_score, classification_report\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense , Dropout , Embedding, LSTM, Input, merge,  Concatenate \n",
        "from keras.models import Sequential\n",
        "from keras.layers import  LSTM, Embedding, Dropout, Activation,CuDNNLSTM\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, Flatten\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.layers import  Conv1D,  Flatten, MaxPooling1D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import backend as k\n",
        "from keras.engine.topology import Layer\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwTynSTan3OP",
        "colab_type": "text"
      },
      "source": [
        "The model are as follows\n",
        "\n",
        "\n",
        "1.   Simple LSTM\n",
        "2.   Bidirectional lstm (Bi-LSTM)\n",
        "3.   CNN -LSTM\n",
        "4.   Bi-LSTM with attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQXp79Q3n_7-",
        "colab_type": "text"
      },
      "source": [
        "# Data pre processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTRUHyWTn-oX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data cleaning process 1 - Faster\n",
        "tok = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9]+'\n",
        "pat2 = r'https?://[A-Za-z0-9./]+'\n",
        "combined_pat = r'|'.join((pat1, pat2))\n",
        "\n",
        "def tweet_cleaner(text):\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    stripped = re.sub(combined_pat, '', souped)\n",
        "    try:\n",
        "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        clean = stripped\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
        "    lower_case = letters_only.lower()\n",
        "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
        "    # I will tokenize and join together to remove unneccessary white spaces\n",
        "\n",
        "    words = tok.tokenize(lower_case) \n",
        "    words = str(TextBlob(words).correct())\n",
        "    w = Word(words)\n",
        "    words = w.lemmatize()\n",
        "    return (\" \".join(words)).strip()\n",
        "\n",
        "\n",
        "#nums = [0,1600000]\n",
        "#%time\n",
        "#print(\"Cleaning and parsing the tweets...\\n\")\n",
        "#clean_tweet_texts = []\n",
        "#for i in range(nums[0],nums[1]):\n",
        "    #if( (i+1)%10000 == 0 ):\n",
        "       # print (\"Tweets %d of %d has been processed\", i+1, nums[1] )\n",
        "  \n",
        "\n",
        "\n",
        "#clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
        "#clean_df['label'] = new_df.sentiment\n",
        "#clean_df.head()\n",
        "#clean_df.to_csv('/content/drive/My Drive/clean_tweet1.csv',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUZP4y0BosG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data cleaning process 1 - Slower\n",
        "\n",
        "punctuation  =  '!\"#$%^\\'()*&-,+.:;<=>?[\\\\]_/{|}~'\n",
        "def clean_function(text):\n",
        "  text = text.lower()\n",
        "  text = ''.join([c for c in text if c not in punctuation ])\n",
        "  text = re.sub('[0-9]+', '', text)\n",
        "  new_text = []\n",
        "  text_split = text.split()\n",
        "  for word in text_split:\n",
        "    if(word[0] != '@') and ('http' not in word) and ( word.isdigit() == False):\n",
        "      word = str(TextBlob(word).correct())\n",
        "      w = Word(word)\n",
        "      word = w.lemmatize()\n",
        "      #word = PorterStemmer().stem(word)\n",
        "      new_text.append(word)\n",
        "  return new_text\n",
        "\n",
        "def new_clean_function(text):\n",
        "  new_text = []\n",
        "  text = re.sub('[0-9]+', '', str(text))\n",
        "  text_split = text.split()\n",
        "  for word in text_split:\n",
        "    word = str(TextBlob(word).correct())\n",
        "    w = Word(word)\n",
        "    word = w.lemmatize()\n",
        "    new_text.append(word)\n",
        "  return new_text\n",
        "\n",
        "##nlpdata_train =  pd.read_csv('/content/drive/My Drive/clean_tweet1.csv',sep=',')\n",
        "#twitter_train_data = nlpdata_train[[ 'label','text']].rename(columns={0:'label','text':'sentence'})\n",
        "#twitter_train_data.head(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3jQT0h8tUPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import data from the drive\n",
        "nlpdata_train =  pd.read_csv('/content/drive/My Drive/clean_tweet1.csv',sep=',')\n",
        "twitter_train_data = nlpdata_train[[ 'label','text']].rename(columns={0:'label','text':'sentence'})\n",
        "twitter_train_data1 = twitter_train_data.sample(10000)\n",
        "twitter_train_data1 = twitter_train_data1.reset_index(drop= True)\n",
        "twitter_train_data1.sentence = twitter_train_data1.sentence.apply(lambda x : re.sub('[0-9]+', '', str(x)).split())\n",
        "Counter(np.array(twitter_train_data1['label']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDL6sUxItxJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build Vocabulary\n",
        "count = []\n",
        "for i in range(len(twitter_train_data1)):\n",
        "  text = twitter_train_data1.sentence[i]\n",
        "  for word in text:\n",
        "    count.append(word)\n",
        "vocab = list(OrderedDict.fromkeys(sorted(count )))\n",
        "\n",
        "def sentence_to_int(text):\n",
        "  convert_int = []\n",
        "  convert_int.append([vocab_to_int[word] for word in text])\n",
        "  return convert_int\n",
        "\n",
        "\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab,1)}\n",
        "\n",
        "twitter_train_data1.sentence = twitter_train_data1.sentence.apply(lambda x:  list(chain.from_iterable(sentence_to_int(x))))\n",
        "#twitter_train_data1.sentence = twitter_train_data1.sentence.apply(lambda x: list(chain.from_iterable(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvhhUZJwt4tV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert text to integers \n",
        "max_length = []\n",
        "remove = []\n",
        "for i in range(len(twitter_train_data1.sentence)):\n",
        "  each_element =len(twitter_train_data1.sentence[i])\n",
        "  max_length.append(each_element)\n",
        "  if each_element ==0:\n",
        "    remove.append(i)\n",
        "max(max_length)\n",
        "\n",
        "twitter_train_data1 =twitter_train_data1.drop(remove, axis=0).reset_index(drop= True)\n",
        "twitter_train_data1.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbyBKIASuI5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copy the data set and work on the copied dataset\n",
        "twitter_train_data_2 = twitter_train_data1.copy(deep= True)\n",
        "twitter_train_data_3 = twitter_train_data1.copy(deep= True)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mQ9s1K-vcWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pad input such tht each sentence has equal length\n",
        "\n",
        "#pad sequence -1\n",
        "def pad_features(x,seq_length):\n",
        "  x = x[:seq_length]+[0]*(seq_length - len(x))\n",
        "  return x\n",
        "  \n",
        "twitter_train_data_2.sentence = twitter_train_data_2.sentence.apply(lambda x: pad_features(x, 32))\n",
        "\n",
        "\n",
        "#pad sequence -1\n",
        "def trimmer(x, size, filler=0):\n",
        "   return list(islice(chain(x, repeat(filler)), size))\n",
        "\n",
        "twitter_train_data_3.sentence = twitter_train_data_3.sentence.apply(lambda x: trimmer(x, 30, filler=0))\n",
        "twitter_train_data_3.sentence = twitter_train_data_3.sentence.apply(lambda x:  np.array((x)))\n",
        "\n",
        "\n",
        "\n",
        "#reshape data\n",
        "def reshape_sentence(x):\n",
        "  return np.asarray(x).reshape(1,30)\n",
        "\n",
        "def reshape_label(x):\n",
        "  return np.asarray(x).reshape(1,1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "939wBhijwDxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#seperate data into train and test \n",
        "\n",
        "def data_extract_train(x, length):\n",
        "  train_x = np.zeros((1,30))\n",
        "  for i in range(length):\n",
        "    train_x = np.append(train_x,np.array(x[i]).reshape(1,30) ,axis = 0)\n",
        "  return train_x[1:,:]\n",
        "\n",
        "def data_extract_train_label(x, length):\n",
        "  train_y = np.zeros((1))\n",
        "  for i in range(length):\n",
        "    train_y = np.append(train_y,np.array(x[i]).reshape(-1) ,axis = 0)\n",
        "  return train_y[1:]\n",
        "\n",
        "split_frac = 0.8\n",
        "split_idx = int(len(twitter_train_data_3)*split_frac)\n",
        "Training_data , remainging_data = twitter_train_data_3.iloc[:split_idx,:], twitter_train_data_3.iloc[split_idx:,:]\n",
        "\n",
        "test_idx = int(len(remainging_data)*0.5)\n",
        "Validation_data = remainging_data.iloc[:test_idx,:].reset_index(drop= True)\n",
        "Testing_data = remainging_data.iloc[test_idx:,:].reset_index(drop= True)\n",
        "\n",
        "\n",
        "train_x = Training_data['sentence'].to_numpy()\n",
        "train_y = Training_data['label'].to_numpy()\n",
        "train_x = np.array(list(chain.from_iterable(train_x))).reshape(-1,30)\n",
        "\n",
        "\n",
        "valid_x = Validation_data['sentence'].to_numpy()\n",
        "valid_y = Validation_data['label'].to_numpy()\n",
        "valid_x = np.array(list(chain.from_iterable(valid_x))).reshape(-1,30)\n",
        "\n",
        "test_x = Testing_data['sentence'].to_numpy() \n",
        "test_y = Testing_data['label'].to_numpy()\n",
        "test_x = np.array(list(chain.from_iterable(test_x))).reshape(-1,30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6AYFYZPwv6y",
        "colab_type": "text"
      },
      "source": [
        "#Model 1: Simple LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg_jpEDSweU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating tensor dataset\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "#dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "#shuffle training data\n",
        "train_loader = DataLoader(train_data ,batch_size= batch_size , shuffle = True , drop_last=True)\n",
        "valid_loader  = DataLoader(valid_data ,batch_size= batch_size , shuffle = True, drop_last=True )\n",
        "test_loader = DataLoader(test_data ,batch_size= batch_size , shuffle = True, drop_last=True )\n",
        "\n",
        "\n",
        "#obtain a batch of training\n",
        "data_iter = iter(train_loader)\n",
        "sample_x , sample_y = data_iter.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIxVr_Vzw-wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn \n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "  \"\"\"\n",
        "  LSTM modeul used for sentiment analysis\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, vocab_size, ouput_size , embedding_dim ,hidden_dim, n_layer , drop_prob = 0.5):\n",
        "    \"\"\"\n",
        "    initalize the model by setting up the layer\n",
        "\n",
        "    \"\"\"\n",
        "    super(SentimentRNN, self).__init__()\n",
        "\n",
        "    self.output_size = output_size\n",
        "    self.n_layer = n_layer\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    #embedding and LSTM layers\n",
        "    self.embedding = nn.Embedding(vocab_size , embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim , hidden_dim , n_layer , dropout = drop_prob , batch_first = True)\n",
        "\n",
        "    #dropout layer\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    #liner and Sigmoid layer\n",
        "    self.fc = nn.Linear(hidden_dim , output_size)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def forward(self , x, hidden):\n",
        "    \"\"\"\n",
        "    Perform a forward pass of the model on some input and hidden state\n",
        "\n",
        "    \"\"\"\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    #embedding and lstm_out\n",
        "    x = x.long()\n",
        "    embeds = self.embedding(x)\n",
        "    lstm_out , hidden = self.lstm(embeds , hidden)\n",
        "\n",
        "\n",
        "    #stack up lstm outputs\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "\n",
        "    #dropout and fully connected layer \n",
        "\n",
        "    out = self.dropout(lstm_out)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    #sigmoid function\n",
        "    sig_out = self.sig(out)\n",
        "\n",
        "    #reshape to be batch_size first\n",
        "    sig_out = sig_out.view(batch_size , -1)\n",
        "    sig_out = sig_out[:,-1] #get last batch label\n",
        "\n",
        "    #return last sigmoid output and the hidden state\n",
        "    return sig_out , hidden \n",
        "\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    \"\"\"\n",
        "    intialize hidden state\n",
        "    \"\"\"\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    hidden = (weight.new(self.n_layer , batch_size , self.hidden_dim).zero_(),\n",
        "              weight.new(self.n_layer, batch_size , self.hidden_dim).zero_())\n",
        "    \n",
        "    return hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxGseG01xERC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab_to_int) +1\n",
        "output_size = 1\n",
        "embedding_dim = 200\n",
        "hidden_dim = 512\n",
        "n_layer = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size,output_size, embedding_dim, hidden_dim, n_layer, drop_prob=0.5)\n",
        "print(net)\n",
        "\n",
        "\n",
        "#triaining\n",
        "lr = 0.001\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcrfjjgtxHDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "counter = 0\n",
        "\n",
        "print_every = 100\n",
        "\n",
        "clip = 5 #gradient clipping\n",
        "\n",
        "net.train()\n",
        "\n",
        "for e in range(epochs):\n",
        "  #initialize the hidden state\n",
        "  h = net.init_hidden(batch_size)\n",
        "\n",
        "  #batch loop\n",
        "\n",
        "  for inputs ,labels in train_loader:\n",
        "    counter += 1\n",
        "\n",
        "\n",
        "\n",
        "    #create new variables for the hidden state, otherwize\n",
        "    #wed backpropagate through the entire training history\n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    #zero accumalute gradients\n",
        "    net.zero_grad()\n",
        "\n",
        "    #get output from the model\n",
        "    output, h = net(inputs, h)\n",
        "\n",
        "    #calculate the loss  and perform backprop\n",
        "    loss = criterion(output.squeeze(), labels.float())\n",
        "    loss.backward()\n",
        "    \n",
        "\n",
        "    #clip_grad_norm helps prvent the exploding gradient problem in RNN\n",
        "    nn.utils.clip_grad_norm(net.parameters(),clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    #loss stats\n",
        "    if counter % print_every ==0:\n",
        "      #get validation loss-\n",
        "      val_h = net.init_hidden(batch_size)\n",
        "\n",
        "      val_losses = []\n",
        "      net.eval()\n",
        "\n",
        "      for inputs ,labels in valid_loader:\n",
        "\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "        ouput, val_h = net(inputs, val_h)\n",
        "        val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "\n",
        "      net.train()\n",
        "      print(\"Epoch:{}/{}\".format(e+1,epochs),\n",
        "            \"Steps: {}...\".format(counter),\n",
        "            \"Loss: {:.6f}\".format(loss.item()),\n",
        "            \"Val loss: {:.6f}\".format(np.mean(val_losses)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxURtDPzxiCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "#init hidden state\n",
        "h= net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "\n",
        "for inputs , labels in test_loader:\n",
        "\n",
        "  #creating new variable for the hidden state, otherwise\n",
        "  #we'd backdrop through the entire training history\n",
        "\n",
        "  h = tuple([each.data for each in h])\n",
        "\n",
        "  #get predicted outputs\n",
        "  output , h = net(inputs,h)\n",
        "\n",
        "  #calulate loss\n",
        "  test_loss = criterion(output.squeeze() , labels.float())\n",
        "  test_losses.append(test_loss.item())\n",
        "\n",
        "  #convert output probabilities to predict 0 or 1\n",
        "  pred = torch.round(output.squeeze()) # rounds to the nearest integer\n",
        "\n",
        "  #compare\n",
        "  correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "\n",
        "  correct = np.squeeze(correct_tensor.numpy())\n",
        "  num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "print('Test loss: {:.3f}'.format(np.mean(test_losses)))\n",
        "\n",
        "\n",
        "#accuracy over all test\n",
        "test_acc = num_correct/ len(test_loader.dataset)\n",
        "print('Test accuracy : {:.3f}'.format(test_acc))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o9ZZ3Iaxo-9",
        "colab_type": "text"
      },
      "source": [
        "#Model 2: Bi- -LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MuBqhsKxmtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshape the data for this and further models\n",
        "train_y = train_y.reshape(-1,1)\n",
        "valid_y = valid_y.reshape(-1,1)\n",
        "test_y = test_y.reshape(-1,1) \n",
        "\n",
        "max_features = len(vocab_to_int)+5\n",
        "max_length = 30\n",
        "\n",
        "def generator(X_data, y_data, batch_size):\n",
        "\n",
        "  samples_per_epoch = X_data.shape[0]\n",
        "  number_of_batches = samples_per_epoch/batch_size\n",
        "  counter=0\n",
        "\n",
        "  while 1:\n",
        "\n",
        "    X_batch = np.array(X_data[batch_size*counter:batch_size*(counter+1)]).astype('float32')\n",
        "    y_batch = np.array(y_data[batch_size*counter:batch_size*(counter+1)]).astype('float32')\n",
        "    counter += 1\n",
        "    yield X_batch,y_batch\n",
        "\n",
        "    #restart counter to yeild data in the next epoch as well\n",
        "    if counter >= number_of_batches:\n",
        "        counter = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbUqLA9Xx1sC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rms2 = RMSprop()\n",
        "#model\n",
        "bilstm_model = Sequential()\n",
        "bilstm_model.add(Embedding(max_features , 200, input_length= max_length))\n",
        "bilstm_model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
        "bilstm_model.add(Dropout(0.7))\n",
        "bilstm_model.add(Bidirectional(LSTM(128)))\n",
        "bilstm_model.add(Dropout(0.7))\n",
        "bilstm_model.add(Dense(1, activation='sigmoid'))\n",
        "bilstm_model.compile( optimizer=rms2 ,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(bilstm_model.summary())\n",
        "bilstm_model.fit_generator(generator(train_x,train_y,1000), steps_per_epoch=20 ,epochs=10, verbose=1, callbacks=None, validation_data=generator(valid_x,valid_y,1000), validation_steps=5, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H-C1-tuyRHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prediction\n",
        "y_pred_bilstm_prob = bilstm_model.predict(test_x)\n",
        "y_pred_bilstm_classes = bilstm_model.predict_classes(test_x)\n",
        "\n",
        "\n",
        "#prediction Statistics\n",
        "score_bilstm = bilstm_model.evaluate(test_x, test_y, verbose = 1)\n",
        "bilstm_accuracy = accuracy_score(test_y, y_pred_bilstm_classes)\n",
        "bilstm_precision = precision_score(test_y, y_pred_bilstm_classes)\n",
        "rocAuc_bilstm = roc_auc_score(test_y, y_pred_bilstm_classes)\n",
        "falsePositiveRate, truePositiveRate, _ = roc_curve(test_y,y_pred_bilstm_prob)\n",
        "\n",
        "\n",
        "#ROC curve\n",
        "plt.figure()\n",
        "plt.plot(falsePositiveRate, truePositiveRate, color='green',\n",
        "         lw=3, label='ROC curve (area = %0.2f)' % rocAuc_bilstm)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC of Sentiment Analysis using BiLSTM model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#accuracy and precsion\n",
        "print(bilstm_accuracy) \n",
        "print(bilstm_precision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw5FuMx_yZXn",
        "colab_type": "text"
      },
      "source": [
        "#Model 3:  CNN-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoCOpeA2yFYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "#model\n",
        "cnn_lstm = Sequential()\n",
        "cnn_lstm.add(Embedding(max_features , 200, input_length= max_length))\n",
        "cnn_lstm.add(Conv1D(filters=64, kernel_size=5, activation='relu', padding='causal'))\n",
        "cnn_lstm.add(MaxPooling1D(pool_size=2))\n",
        "cnn_lstm.add(Dropout(0.7))\n",
        "cnn_lstm.add(LSTM(units=256))\n",
        "cnn_lstm.add(Dropout(0.7))\n",
        "cnn_lstm.add(Dense(1, activation='sigmoid'))\n",
        "cnn_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(cnn_lstm.summary())\n",
        "\n",
        "\n",
        "# model training\n",
        "cnn_lstm.fit_generator(generator(train_x,train_y,1000), steps_per_epoch=50 ,epochs=10, verbose=1, callbacks=None, validation_data=generator(valid_x,valid_y,1000), validation_steps=3, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBhuvSAmymon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prediction\n",
        "y_predict_cnn_lstm_prob = cnn_lstm.predict(test_x)\n",
        "y_pred_cnn_lstm_classes = cnn_lstm.predict_classes(test_x)\n",
        "\n",
        "#analyze the results\n",
        "#prediction Statistics\n",
        "score_cnn_lstm = cnn_lstm.evaluate(test_x, test_y, verbose = 1)\n",
        "cnn_lstm_accuracy = accuracy_score(test_y, y_pred_cnn_lstm_classes)\n",
        "cnn_lstm_precision = precision_score(test_y, y_pred_cnn_lstm_classes)\n",
        "rocAuc_cnn_lstm= roc_auc_score(test_y, y_pred_cnn_lstm_classes)\n",
        "falsePositiveRate, truePositiveRate, _ = roc_curve(test_y, y_predict_cnn_lstm_prob)\n",
        "\n",
        "#ROC AUC curve\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(falsePositiveRate, truePositiveRate, color='green',\n",
        "         lw=3, label='ROC curve (area = %0.2f)' % rocAuc_cnn_lstm)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC of Sentiment Analysis using CNN-LSTM model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#accuracy and precsion\n",
        "print(cnn_lstm_accuracy )\n",
        "print(cnn_lstm_precision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI_22ccozKSj",
        "colab_type": "text"
      },
      "source": [
        "#Model 4: Bi-LSTM with Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnJBU8dJzPRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "#attenstion Layer\n",
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "    def call(self, features, hidden):\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "Bilstm_attn_input = tf.keras.layers.Input(shape=(max_length,), dtype='int32')\n",
        "\n",
        "embedded_sequences = tf.keras.layers.Embedding(max_features, 200, input_length=max_length)(Bilstm_attn_input)\n",
        "lstm, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional \\\n",
        "    (tf.keras.layers.LSTM\n",
        "     (256,\n",
        "      dropout=0.2,\n",
        "      return_sequences=True,\n",
        "      return_state=True,\n",
        "      recurrent_activation='relu',\n",
        "      recurrent_initializer='glorot_uniform'))(embedded_sequences)#(lstm)\n",
        "\n",
        "state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
        "\n",
        "\n",
        "context_vector, attention_weights = Attention(30)(lstm, state_h)\n",
        "output = keras.layers.Dense(1, activation='sigmoid')(context_vector)\n",
        "bilstm_attn_model = keras.Model(inputs=Bilstm_attn_input, outputs=output)\n",
        "\n",
        "# summarize layers\n",
        "print(bilstm_attn_model.summary())\n",
        "rms = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
        "bilstm_attn_model.compile(loss='binary_crossentropy', optimizer=rms , metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKosNl-VzgQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bilstm_attn_model.fit_generator(generator(train_x,train_y,1000),steps_per_epoch= 30,epochs=15, verbose=1, callbacks=None, validation_data=generator(valid_x,valid_y,1000), validation_steps=5, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8840G_Rzi_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prediction\n",
        "y_predict_bilstm_attn_prob = bilstm_attn_model.predict(test_x)\n",
        "y_predict_bilstm_attn_classes = (y_predict_bilstm_attn_prob> 0.5).astype(np.int)\n",
        "\n",
        "#analyze the results\n",
        "#prediction Statistics\n",
        "score_bilstm_attn = bilstm_attn_model.evaluate(test_x, test_y, verbose = 1)\n",
        "bilstm_attn_accuracy = accuracy_score(test_y, y_predict_bilstm_attn_classes)\n",
        "bilstm_attn_precision = precision_score(test_y, y_predict_bilstm_attn_classes)\n",
        "rocAuc_bilstm_attn = roc_auc_score(test_y, y_predict_bilstm_attn_classes)\n",
        "falsePositiveRate, truePositiveRate, _ = roc_curve(test_y, y_predict_bilstm_attn_prob)\n",
        "\n",
        "#ROC AUC curve\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(falsePositiveRate, truePositiveRate, color='green',\n",
        "         lw=3, label='ROC curve (area = %0.2f)' % rocAuc_bilstm_attn)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC of Sentiment Analysis using Bi-LSTM_attn model')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#accuracy and precsion\n",
        "print(bilstm_attn_accuracy )\n",
        "print(bilstm_attn_precision)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}